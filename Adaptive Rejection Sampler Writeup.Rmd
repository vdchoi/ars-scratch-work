---
title: "Adaptive Rejection Sampler Write-up"
author: Zhuang Liu, John Vouvakis Manousakis, Victor Choi
output:
  pdf_document: default
  html_document: default
---

**Overall Approach**  
Our approach to create an adaptive rejection sampling package closely follows the details described in Section 2.2 of Gilks et al (1992). At a high level, our package ‘ars’ takes in an arbitrary log-concave input density, and outputs a random sample from the input density using standard principles of rejection sampling. To improve the performance of the sampling process, we implement methods inspired from Gilks et al (1992) to limit the amount of times the input density needs to be evaluated, in order to reduce costs attributed to the evaluation of a complex input density when taking a large sample.

**Checks - Log Concavity, Bounds**  
A series of automated sanity checks are performed before the sampling algorithm is initiated. If the domain is not bounded, it is verified that the value of the density function at Inf evaluates to zero without overflowing. Then it is verified that the density function does evaluate to negative values. Finally, the derivative of the log of the function is being evaluated and it is verified that it is constantly decreasing, which signifies log-concavity. The derivative is obtained on 10,000 points that are centered around the approximate mean and have a dispersion defined by the approximate variance of the given density function.  

Limitations  
The function cannot handle cases when the given density has the potential to cause numerical overflow. This can happen when trying to sample from a density that has an unbounded domain, and indeed theoretically goes to zero when x goes to infinity, but causes an overflow when evaluated numerically. An example of such a density would be 

$$
f(x) = 1 - frac{exp(x)-exp(-x)}{exp(x)+exp(-x)}
$$

$$
X \in [1, \infty]
$$

In this case 

The derivative of the log of f is 
$$
-((2 E^(2 x))/(1 + E^(2 x)))
$$
which can be expressed as 
$$
-(2/(1 + E^(-2 x))) 
$$
to eliminate overflow.

After all checks pass, we proceed with the sampling process.

**Sampling**  
The first step of the adaptive rejection sampling process is to sample from a piecewise exponential function, corresponding to the exponent of the upper hull function of the given log input density. To do so, we split the sampling into two steps. 

First, we choose which piece of the function to sample from. To do so, we sample from a multinomial, with a probability vector corresponding to the relative area of the upper hull between each intersection point. This will output a vector of indexes, that informs the sampler of which section of the piecewise exponential function to sample from.

Next, given a vector of indexes, we transform a vector of uniform(0,1) samples to our corresponding input density, through Inverse Transform Sampling. Details described below

## Sampling from a piecewise exponential density function

![Piecewise exponential](figures/density1.PNG){width=50%}

$s(k)$ is a piecewise function, having parts $j \in \{1,2,...,K\}$ Sampling random variables from that function can be performed as follows.
Let $\pi_j$ denote the area underneath part $j$, having the domain $(z_j, z_{j+1})$. Drawing from a multinomial distribution, given the $\pi_j$ values, the problem can be broken into the $K$ individual parts.


![Translated exponential density](figures/density2.PNG){width=50%}

The problem has been reduced to sampling from a shifted exponential density. The domain of the PDF is $D = (z_j, z_{j+1})$.

Let $c = \int_D \exp(u_k(x))dx$

$$
s_k(x) = \frac{1}{c} \exp(u_k(x)) = 
\frac{1}{c} \exp \left( \frac{u_k(z_{j+1})-u_k(z_j)}{z_{j+1}-z_j} (x - z_j) + u_k(z_j) \right)
$$
$$
= \frac{1}{c} \exp \left( 
\frac{u_k(z_{j+1}) - u_k(z_j)}{z_{j+1}-z_j} x - 
\frac{u_k(z_{j+1}) - u_k(z_j)}{z_{j+1}-z_j} z_j + u_k(z_j)
\right)
$$


$$
= \frac{1}{c} \exp \left( \alpha x + \beta \right)
$$

where we have denoted

$$
\alpha = \frac{u_k(z_{j+1}) - u_k(z_j)}{z_{j+1}-z_j}
$$


$$
\beta = -\frac{u_k(z_{j+1}) - u_k(z_j)}{z_{j+1}-z_j} z_j + u_k(z_j)
$$

The CDF can be obtained by integration, as follows

$$
S_k(x) = \frac{1}{\pi_j} \int_{z_j}^x s_k(y) dy 
= \frac{1}{\pi_j} \int_{z_j}^x \frac{1}{c}\exp \left( \alpha x + \beta \right) dx
$$


$$
= \frac{e^\beta \left( e^{\alpha x} - e^{\alpha z_j} \right)}{\alpha c \pi_j}
$$

Where

$$
\pi_j = \frac{e^\beta \left( e^{\alpha z_{j+1}} - e^{\alpha z_j} \right)}{\alpha c}
$$

The inverse CDF can also be obtained analytically.

$$
p = S_k(x) = \frac{e^\beta \left( e^{\alpha x} - e^{\alpha z_j} \right)}{\alpha c \pi_j} =>
$$

$$
S_k^{-1}(p) = \frac{1}{\alpha} \log(e^{\alpha z_j} + \alpha c \pi_j e^{-\beta} p)
$$


Samples can be drawn from a random variable $p \sim U(0,1)$, and then the following transformation can be applied to have them follow the corresponding part $k$ of the piecewise exponential distribution, as follows

$$
x = S_k^{-1}(p)
$$

Last, given our sampled values, we perform standard squeezing and rejection tests, using the lower and upper hulls functions of the log input density function. For all points evaluated in the rejection step, the evaluated points are added back into the list of points used to initialize the sampler. This process repeats until the required sample size is reached.


**Contributions**  
For this project, we three worked together throughout much of the process. Most of the time was spent pair-programming, however we assigned each section for one of us to lead. In particular, Zhong was responsible for designing/updating the data structures, along with leading us on how to do documentation. John took the lead in the log-concavity/bounds tests, along with the theoretical calculations for the math. Victor was responsible for coding the sampling and rejection/squeezing steps, and took the lead on writing the write-up. 




